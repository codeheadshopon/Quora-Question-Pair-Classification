
'''Error: TypeError: ('Not a Keras tensor:', <keras.models.Sequential object at 0x7f882ba5eed0>)'''


from __future__ import print_function
import csv, datetime, time, json
from keras.callbacks import Callback, ModelCheckpoint
from sklearn.model_selection import train_test_split
import sys
import numpy.random as rng
import numpy as np
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Input, Lambda,GRU,Embedding, LSTM
from keras import backend as K
from keras.layers import Merge
from keras.optimizers import RMSprop
from keras.layers import Embedding, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, Lambda

reload(sys)
sys.setdefaultencoding('utf-8')

LABEL_TRAINING_DATA_FILE = 'label_train.npy'
WORD_EMBEDDING_MATRIX_FILE = 'word_embedding_matrix.npy'
NB_WORDS_DATA_FILE = 'nb_words.json'
RNG_SEED = 13371447
VALIDATION_SPLIT = 0.02
TEST_SPLIT = 0.02
MAX_NB_WORDS = 200000
MAX_SEQUENCE_LENGTH = 25
EMBEDDING_DIM = 300

train_q1_data=np.load(open('train_Q1', 'rb'))
train_q2_data=np.load(open('train_Q2', 'rb'))
test_q1_data=np.load(open('test_Q1', 'rb'))
test_q2_data=np.load(open('test_Q2', 'rb'))
labels = np.load(open(LABEL_TRAINING_DATA_FILE, 'rb'))
word_embedding_matrix = np.load(open(WORD_EMBEDDING_MATRIX_FILE, 'rb'))
with open(NB_WORDS_DATA_FILE, 'r') as f:
    nb_words = json.load(f)['nb_words']


'''Creating The Training and Validation Set'''
X = np.stack((train_q1_data, train_q2_data), axis=1)
y = labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)

Q1_train = X_train[:, 0]
Q2_train = X_train[:, 1]
Q1_test = X_test[:, 0]
Q2_test = X_test[:, 1]

def base_network(inputs):
    model1=Sequential()
    model1.add(Embedding(nb_words + 1, EMBEDDING_DIM, input_length=MAX_SEQUENCE_LENGTH, mask_zero=True, trainable=False,
                         weights=[word_embedding_matrix],input_shape=(inputs,)))
    model1.add(LSTM(output_dim=128, return_sequences=False, go_backwards=True, init='he_normal',activation='relu'))
    model1.add(Dropout(0.5))
    return model1

input_a = Input(shape=(25,))
input_b = Input(shape=(25,))

model1 = base_network(input_a)
model2 = base_network(input_b)

distance = Lambda(Dense(1,activation='sigmoid'),
                  output_shape=[128])([model1, model2])

model = Model([input_a, input_b], distance)

rms = RMSprop()
model.compile(loss='binary_crossentropy', optimizer=rms)


F3="Epochs/weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5"
filepath=F3
callbacks = [ModelCheckpoint(filepath, monitor='val_acc', save_best_only=True)]

model.fit([Q1_train,Q2_train],y_train,nb_epoch=80, batch_size=128,verbose=1,shuffle=True,callbacks=callbacks,validation_data=([Q1_test,Q2_test],y_test))
